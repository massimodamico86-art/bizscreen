---
phase: 03-auth-hardening
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/116_api_rate_limiting.sql
autonomous: true

must_haves:
  truths:
    - "Database has api_rate_limits table for tracking API requests"
    - "check_rate_limit() function returns allowed/denied with retry info"
    - "Rate limit check is atomic (no race conditions)"
    - "Old rate limit records are cleaned up automatically"
  artifacts:
    - path: "supabase/migrations/116_api_rate_limiting.sql"
      provides: "Rate limiting infrastructure"
      contains: "check_rate_limit"
  key_links:
    - from: "supabase/migrations/116_api_rate_limiting.sql"
      to: "api_rate_limits table"
      via: "CREATE TABLE"
      pattern: "CREATE TABLE.*api_rate_limits"
---

<objective>
Create database-level rate limiting infrastructure

Purpose: Implement PostgreSQL-based rate limiting following the existing login_attempts pattern. This provides server-side rate limiting that cannot be bypassed by clients, using a fixed 15-minute window as specified in CONTEXT.md.

Output: Migration file with api_rate_limits table and check_rate_limit() function that services can call.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-auth-hardening/03-CONTEXT.md
@.planning/phases/03-auth-hardening/03-RESEARCH.md
@supabase/migrations/103_login_attempt_lockout.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create rate limiting migration</name>
  <files>supabase/migrations/116_api_rate_limiting.sql</files>
  <action>
Create supabase/migrations/116_api_rate_limiting.sql with:

1. Table creation:
```sql
-- ============================================
-- API Rate Limiting
-- ============================================
-- Tracks API request counts per identifier (user_id or IP)
-- and action type. Enforces rate limits with fixed 15-minute windows.
-- ============================================

CREATE TABLE IF NOT EXISTS api_rate_limits (
  id uuid PRIMARY KEY DEFAULT gen_random_uuid(),
  identifier text NOT NULL,        -- user_id or IP address
  action text NOT NULL,            -- 'media_upload', 'scene_create', etc.
  created_at timestamptz DEFAULT now()
);

-- Index for fast lookups during rate limit checks
CREATE INDEX IF NOT EXISTS idx_rate_limits_lookup
  ON api_rate_limits (identifier, action, created_at DESC);

-- Index for cleanup of old records
CREATE INDEX IF NOT EXISTS idx_rate_limits_time
  ON api_rate_limits (created_at);

-- Enable RLS
ALTER TABLE api_rate_limits ENABLE ROW LEVEL SECURITY;

-- Only allow insert from authenticated users
CREATE POLICY "Authenticated users can insert rate limit records"
  ON api_rate_limits FOR INSERT
  TO authenticated
  WITH CHECK (true);

-- Service role can read for monitoring
CREATE POLICY "Service role can read rate limits"
  ON api_rate_limits FOR SELECT
  USING (auth.role() = 'service_role');
```

2. Rate limit check function (atomic - prevents race conditions):
```sql
-- ============================================
-- Function: Check and record rate limit
-- ============================================
-- Atomically checks if identifier has exceeded rate limit
-- and records the current request if allowed.
-- Returns: { allowed: boolean, current_count: int, retry_after_seconds: int }
-- ============================================
CREATE OR REPLACE FUNCTION public.check_rate_limit(
  p_identifier text,
  p_action text,
  p_max_requests integer,
  p_window_minutes integer DEFAULT 15
)
RETURNS jsonb
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  v_count integer;
  v_window_start timestamptz := now() - (p_window_minutes || ' minutes')::interval;
  v_oldest_in_window timestamptz;
  v_retry_seconds integer;
BEGIN
  -- Lock to prevent race conditions
  PERFORM pg_advisory_xact_lock(hashtext(p_identifier || p_action));

  -- Count requests in current window
  SELECT COUNT(*), MIN(created_at)
  INTO v_count, v_oldest_in_window
  FROM api_rate_limits
  WHERE identifier = p_identifier
    AND action = p_action
    AND created_at > v_window_start;

  -- Check if limit exceeded
  IF v_count >= p_max_requests THEN
    -- Calculate seconds until oldest request expires
    v_retry_seconds := GREATEST(1, EXTRACT(EPOCH FROM (
      v_oldest_in_window + (p_window_minutes || ' minutes')::interval - now()
    ))::integer);

    RETURN jsonb_build_object(
      'allowed', false,
      'current_count', v_count,
      'retry_after_seconds', v_retry_seconds,
      'limit', p_max_requests
    );
  END IF;

  -- Record this request
  INSERT INTO api_rate_limits (identifier, action)
  VALUES (p_identifier, p_action);

  RETURN jsonb_build_object(
    'allowed', true,
    'current_count', v_count + 1,
    'remaining', p_max_requests - v_count - 1,
    'limit', p_max_requests
  );
END;
$$;

-- Grant execute to authenticated users
GRANT EXECUTE ON FUNCTION public.check_rate_limit(text, text, integer, integer) TO authenticated;
```

3. Cleanup function:
```sql
-- ============================================
-- Cleanup job: Remove old rate limit records
-- ============================================
-- Records older than 1 day are no longer needed for rate limiting
-- Call from cron or scheduled job
-- ============================================
CREATE OR REPLACE FUNCTION public.cleanup_rate_limits()
RETURNS integer
LANGUAGE plpgsql
SECURITY DEFINER
SET search_path = public
AS $$
DECLARE
  v_deleted integer;
BEGIN
  DELETE FROM api_rate_limits
  WHERE created_at < now() - interval '1 day';

  GET DIAGNOSTICS v_deleted = ROW_COUNT;
  RETURN v_deleted;
END;
$$;

-- Only service role can run cleanup
GRANT EXECUTE ON FUNCTION public.cleanup_rate_limits() TO service_role;
```

4. Comments for documentation:
```sql
-- ============================================
-- Comments
-- ============================================
COMMENT ON TABLE api_rate_limits IS 'Tracks API requests for rate limiting enforcement';
COMMENT ON FUNCTION public.check_rate_limit IS 'Atomically check and record rate limit, returns allowed status with retry info';
COMMENT ON FUNCTION public.cleanup_rate_limits IS 'Remove rate limit records older than 1 day';
```
  </action>
  <verify>
  - File exists: `ls supabase/migrations/116_api_rate_limiting.sql`
  - File contains table creation: `grep "CREATE TABLE.*api_rate_limits" supabase/migrations/116_api_rate_limiting.sql`
  - File contains check function: `grep "check_rate_limit" supabase/migrations/116_api_rate_limiting.sql`
  - File contains advisory lock: `grep "pg_advisory_xact_lock" supabase/migrations/116_api_rate_limiting.sql`
  </verify>
  <done>Migration file creates api_rate_limits table with atomic check_rate_limit() function</done>
</task>

<task type="auto">
  <name>Task 2: Apply migration to local database</name>
  <files>supabase/migrations/116_api_rate_limiting.sql</files>
  <action>
Run the migration against the local Supabase instance:

```bash
npx supabase db push
```

If supabase CLI not available or db push fails, document that migration needs to be applied manually and verify syntax is correct with:

```bash
# Verify SQL syntax (basic check)
psql -c "SELECT 1" 2>/dev/null || echo "psql not available, migration ready for manual apply"
```
  </action>
  <verify>
  - Migration applied or ready for deployment
  - No SQL syntax errors in migration file
  </verify>
  <done>Migration applied or verified ready for deployment</done>
</task>

</tasks>

<verification>
1. Migration file exists at supabase/migrations/116_api_rate_limiting.sql
2. Contains CREATE TABLE api_rate_limits
3. Contains check_rate_limit function with pg_advisory_xact_lock (prevents race conditions)
4. Contains cleanup_rate_limits function
5. RLS policies configured
</verification>

<success_criteria>
- api_rate_limits table created with proper indexes
- check_rate_limit() function returns { allowed, current_count, retry_after_seconds }
- Function uses advisory lock to prevent race conditions
- Cleanup function available for scheduled execution
</success_criteria>

<output>
After completion, create `.planning/phases/03-auth-hardening/03-02-SUMMARY.md`
</output>
